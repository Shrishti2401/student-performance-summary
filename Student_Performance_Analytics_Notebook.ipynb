{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff74d36a",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Student Performance Tracker - EdTech Analytics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b3965",
   "metadata": {},
   "source": [
    "## ðŸ“˜ Introduction\n",
    "\n",
    "In modern education systems, the analysis and prediction of student academic performance have become crucial tools for improving teaching effectiveness and learning outcomes. With the growing availability of student test data, educational institutions can now leverage data analytics to gain actionable insights into learner behavior, subject strengths, participation trends, and exam readiness. These insights not only help teachers personalize their strategies but also enable administrators to allocate academic resources more effectively.\n",
    "\n",
    "This project leverages real-time student data from a JEE coaching institute to assess test-wise academic performance, behavioral engagement, and predictive score modeling. It helps identify at-risk students, high performers, and students needing targeted support, thereby making performance monitoring a more scientific and data-backed process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d367f",
   "metadata": {},
   "source": [
    "## ðŸ” Problem Statement\n",
    "\n",
    "The objective of this project is to analyze how student performance varies based on attributes such as gender, subject-wise accuracy, exam type, and batch. The ultimate institutional goal is to help more students gain admission to Tier-1 colleges like IIT, NIT, and IIIT. This requires tracking student improvement over time, identifying weak and strong subject areas, recognizing exam non-participation patterns, and predicting future exam scores.\n",
    "\n",
    "By using regression modeling (Linear, Lasso, Ridge, and XGBoost), this project aims to forecast students' upcoming JEE scores and segment them based on risk levels. These predictive insights allow educators to intervene early, personalize learning, and drive better student outcomes through data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df8f13",
   "metadata": {},
   "source": [
    "## ðŸ’¡ Why This Project?\n",
    "\n",
    "Data-driven performance analytics is revolutionizing how JEE aspirants prepare for competitive exams. By helping students understand their academic strengths and weaknesses, such systems empower smarter study patterns and strategic preparation. Rather than relying solely on broad assessments, this project provides a focused and personalized view into each studentâ€™s journey â€” helping academic mentors optimize their efforts and ultimately enhance success rates across the institute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b10b2",
   "metadata": {},
   "source": [
    "## ðŸ“Š Dataset Overview\n",
    "\n",
    "- Source: 50+ Excel files (2023â€“2024) containing student test performance across various exam types.\n",
    "- Additional dataset: student details (roll no, name, current batch).\n",
    "- Final consolidated dataset: 13,894 rows Ã— 19 columns after cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0522f0",
   "metadata": {},
   "source": [
    "### ðŸ“¦ Data Processing Steps:\n",
    "- Created `clean_excel_file()` to dynamically parse sheets, headers, and metadata like exam type, date.\n",
    "- Removed unmatched roll numbers, fixed nulls in subject scores.\n",
    "- Final dataset uploaded to MSSQL in two tables:\n",
    "  - `student`: roll no, name, batch\n",
    "  - `student_performance`: all exam-related metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "\n",
    "def infer_exam_date(filename: str):\n",
    "    match = re.search(r\"(\\d{2}-\\d{2}-\\d{4})\", filename)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), \"%d-%m-%Y\").date()\n",
    "    return None\n",
    "\n",
    "def infer_exam_type(filename: str):\n",
    "    exam_types = ['WTM', 'WTA', 'EAMCET', 'ADV', 'BITSAT', 'PTM']\n",
    "    for etype in exam_types:\n",
    "        if etype in filename.upper():\n",
    "            return etype\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "# --- Main Cleaning Function ---\n",
    "def clean_excel_file(filepath: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        \n",
    "        filename = filepath.split('/')[-1]\n",
    "        print(\"Processing file:\", filename)\n",
    "        print(\"File path:\", filepath)\n",
    "        #If more than two sheets are present, then select the second sheet\n",
    "        xls = pd.ExcelFile(filepath)\n",
    "\n",
    "        # List of sheet names\n",
    "        sheet_names = xls.sheet_names\n",
    "        # print(\"Sheets:\", sheet_names)\n",
    "\n",
    "        # Total number of sheets\n",
    "        sheet_count = len(sheet_names)\n",
    "        print(\"Total sheets:\", sheet_count)\n",
    "        if(sheet_count==2) :\n",
    "            sheet=sheet_names[1]\n",
    "        else:\n",
    "            sheet=sheet_names[0]\n",
    "        if sheet_count==0:\n",
    "            raise ValueError(\"No sheets found in the Excel file\")\n",
    "\n",
    "        df_raw = pd.read_excel(filepath, header=None,sheet_name=sheet)\n",
    "        # Define list of required headers\n",
    "        expected_keywords = ['ADM', 'SEC', 'TOT', 'M_M', 'P_R','S NO','MAT_M', 'PHYS_M', 'CHEM_M','roll_no','Rank']\n",
    "\n",
    "        # Find row that contains most of the keywords\n",
    "        header_row_index = None\n",
    "        for i, row in df_raw.iterrows():\n",
    "            matches = sum(any(kw in str(cell) for kw in expected_keywords) for cell in row)\n",
    "            if matches >= 2:  # Threshold: 2 or more keyword matches\n",
    "                header_row_index = i\n",
    "                break\n",
    "        if header_row_index is not None:\n",
    "            df = pd.read_excel(filepath, sheet_name=sheet, header=header_row_index)\n",
    "        else:\n",
    "            raise ValueError(\"No valid header row found\")\n",
    "        # print(f\"Header row index: {header_row_index}\")\n",
    "\n",
    "        #trim extra spaces from col names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        df = df.rename(columns={'ADM NO': 'rollno',\n",
    "                 'STUDENT NAME': 'student_name',\n",
    "                 'M_C': 'math_correct', 'M_W': 'math_wrong', 'M_M\\n100': 'math_tot','MAT_M\\n80' : 'math_tot',\n",
    "                 'M_M\\n80':'math_tot','P_M\\n40' : 'phy_tot','C_M\\n40' : 'chem_tot',\n",
    "                 'PHY_M\\n40': 'phy_tot','CHE_M\\n40' : 'chem_tot','Tot_M\\n160': 'total_marks','TOT\\n160': 'total_marks',\n",
    "                 'P_C': 'phys_correct', 'P_W': 'phys_wrong', 'P_M\\n100': 'phy_tot',\n",
    "                 'C_C': 'chem_correct', 'C_W': 'chem_wrong', 'C_M\\n100': 'chem_tot',\n",
    "                 'Maths_CorrectMarks': 'math_correct',\n",
    "                 'Physics_CorrectMarks': 'phys_correct',\n",
    "                 'Chemistry_CorrectMarks': 'chem_correct',\n",
    "                 'Maths_WrongMarks': 'math_wrong',\n",
    "                 'Physics_WrongMarks': 'phys_wrong',\n",
    "                 'Chemistry_WrongMarks': 'chem_wrong',\n",
    "                 'Maths_Marks': 'math_tot',\n",
    "                 'Physics_Marks': 'phy_tot',\n",
    "                 'Chemistry_Marks': 'chem_tot',\n",
    "                 'Total_Marks': 'total_marks',\n",
    "                 'TOT_M\\n300': 'total_marks',\n",
    "                 'Rank': 'rank','TOT_R':'rank',\n",
    "                 'SEC': 'batch_at_exam'})\n",
    "\n",
    "        \n",
    "        standard_columns = [\n",
    "            'rollno', 'student_name', 'math_correct', 'phys_correct', 'chem_correct',\n",
    "            'math_wrong', 'phys_wrong', 'chem_wrong',\n",
    "            'math_tot', 'phy_tot', 'chem_tot',\n",
    "            'total_marks', 'rank', 'batch_at_exam'\n",
    "        ]\n",
    "        for col in standard_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        df = df[standard_columns]\n",
    "        \n",
    "\n",
    "\n",
    "        # Metadata\n",
    "        df['exam_type'] = infer_exam_type(filename)\n",
    "        df['exam_date'] = infer_exam_date(filename)\n",
    "        df['filename'] = filename\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIPPED] {filepath}: {str(e)}\")\n",
    "        skipped_dir = os.path.join(\"data\", \"raw\", \"skipped\")\n",
    "        os.makedirs(skipped_dir, exist_ok=True)\n",
    "        shutil.move(filepath, os.path.join(skipped_dir, os.path.basename(filepath)))\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac73542",
   "metadata": {},
   "source": [
    "Now exporting all files I noticed somes files was skipped again de-bugged code and loaded file and finally saved into student_data dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d5da05",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(student_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0903e0",
   "metadata": {},
   "source": [
    "(11567, 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df99d61",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
