{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff74d36a",
   "metadata": {},
   "source": [
    "# üìò Student Performance Tracker - EdTech Analytics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b3965",
   "metadata": {},
   "source": [
    "## üìò Introduction\n",
    "\n",
    "In modern education systems, the analysis and prediction of student academic performance have become crucial tools for improving teaching effectiveness and learning outcomes. With the growing availability of student test data, educational institutions can now leverage data analytics to gain actionable insights into learner behavior, subject strengths, participation trends, and exam readiness. These insights not only help teachers personalize their strategies but also enable administrators to allocate academic resources more effectively.\n",
    "\n",
    "This project leverages real-time student data from a JEE coaching institute to assess test-wise academic performance, behavioral engagement, and predictive score modeling. It helps identify at-risk students, high performers, and students needing targeted support, thereby making performance monitoring a more scientific and data-backed process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d367f",
   "metadata": {},
   "source": [
    "## üîç Problem Statement\n",
    "\n",
    "The objective of this project is to analyze how student performance varies based on attributes such as gender, subject-wise accuracy, exam type, and batch. The ultimate institutional goal is to help more students gain admission to Tier-1 colleges like IIT, NIT, and IIIT. This requires tracking student improvement over time, identifying weak and strong subject areas, recognizing exam non-participation patterns, and predicting future exam scores.\n",
    "\n",
    "By using regression modeling (Linear, Lasso, Ridge, and XGBoost), this project aims to forecast students' upcoming JEE scores and segment them based on risk levels. These predictive insights allow educators to intervene early, personalize learning, and drive better student outcomes through data-driven decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df8f13",
   "metadata": {},
   "source": [
    "## üí° Why This Project?\n",
    "\n",
    "Data-driven performance analytics is revolutionizing how JEE aspirants prepare for competitive exams. By helping students understand their academic strengths and weaknesses, such systems empower smarter study patterns and strategic preparation. Rather than relying solely on broad assessments, this project provides a focused and personalized view into each student‚Äôs journey ‚Äî helping academic mentors optimize their efforts and ultimately enhance success rates across the institute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b10b2",
   "metadata": {},
   "source": [
    "## üìä Dataset Overview\n",
    "\n",
    "- Source: 50+ Excel files (2023‚Äì2024) containing student test performance across various exam types.\n",
    "- Additional dataset: student details (roll no, name, current batch).\n",
    "- Final consolidated dataset: 13,894 rows √ó 19 columns after cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367dcbc2",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Data Disclaimer\n",
    "\n",
    "> üì¢ **Note**: The data used in this project is **synthetically generated**  to simulate real-world educational scenarios. It reflects common patterns and structures observed in coaching institutes preparing students for competitive exams like JEE.\n",
    ">\n",
    "> No real student-identifiable information has been used or exposed. The objective is to showcase data analysis, predictive modeling, and dashboarding skills while maintaining strict data integrity and confidentiality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0522f0",
   "metadata": {},
   "source": [
    "### üì¶ Data Processing Steps:\n",
    "- Created `clean_excel_file()` to dynamically parse sheets, headers, and metadata like exam type, date.\n",
    "- Removed unmatched roll numbers, fixed nulls in subject scores,rank,student name\n",
    "- Final dataset uploaded to MSSQL in two tables:\n",
    "  - `student`: roll no, name, batch\n",
    "  - `student_performance`: all exam-related metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "\n",
    "def infer_exam_date(filename: str):\n",
    "    match = re.search(r\"(\\d{2}-\\d{2}-\\d{4})\", filename)\n",
    "    if match:\n",
    "        return datetime.strptime(match.group(1), \"%d-%m-%Y\").date()\n",
    "    return None\n",
    "\n",
    "def infer_exam_type(filename: str):\n",
    "    exam_types = ['WTM', 'WTA', 'EAMCET', 'ADV', 'BITSAT', 'PTM']\n",
    "    for etype in exam_types:\n",
    "        if etype in filename.upper():\n",
    "            return etype\n",
    "    return \"UNKNOWN\"\n",
    "\n",
    "\n",
    "# --- Main Cleaning Function ---\n",
    "def clean_excel_file(filepath: str) -> pd.DataFrame:\n",
    "    try:\n",
    "        \n",
    "        filename = filepath.split('/')[-1]\n",
    "        print(\"Processing file:\", filename)\n",
    "        print(\"File path:\", filepath)\n",
    "        #If more than two sheets are present, then select the second sheet\n",
    "        xls = pd.ExcelFile(filepath)\n",
    "\n",
    "        # List of sheet names\n",
    "        sheet_names = xls.sheet_names\n",
    "        # print(\"Sheets:\", sheet_names)\n",
    "\n",
    "        # Total number of sheets\n",
    "        sheet_count = len(sheet_names)\n",
    "        print(\"Total sheets:\", sheet_count)\n",
    "        if(sheet_count==2) :\n",
    "            sheet=sheet_names[1]\n",
    "        else:\n",
    "            sheet=sheet_names[0]\n",
    "        if sheet_count==0:\n",
    "            raise ValueError(\"No sheets found in the Excel file\")\n",
    "\n",
    "        df_raw = pd.read_excel(filepath, header=None,sheet_name=sheet)\n",
    "        # Define list of required headers\n",
    "        expected_keywords = ['ADM', 'SEC', 'TOT', 'M_M', 'P_R','S NO','MAT_M', 'PHYS_M', 'CHEM_M','roll_no','Rank']\n",
    "\n",
    "        # Find row that contains most of the keywords\n",
    "        header_row_index = None\n",
    "        for i, row in df_raw.iterrows():\n",
    "            matches = sum(any(kw in str(cell) for kw in expected_keywords) for cell in row)\n",
    "            if matches >= 2:  # Threshold: 2 or more keyword matches\n",
    "                header_row_index = i\n",
    "                break\n",
    "        if header_row_index is not None:\n",
    "            df = pd.read_excel(filepath, sheet_name=sheet, header=header_row_index)\n",
    "        else:\n",
    "            raise ValueError(\"No valid header row found\")\n",
    "        # print(f\"Header row index: {header_row_index}\")\n",
    "\n",
    "        #trim extra spaces from col names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        df = df.rename(columns={'ADM NO': 'rollno',\n",
    "                 'STUDENT NAME': 'student_name',\n",
    "                 'M_C': 'math_correct', 'M_W': 'math_wrong', 'M_M\\n100': 'math_tot','MAT_M\\n80' : 'math_tot',\n",
    "                 'M_M\\n80':'math_tot','P_M\\n40' : 'phy_tot','C_M\\n40' : 'chem_tot',\n",
    "                 'PHY_M\\n40': 'phy_tot','CHE_M\\n40' : 'chem_tot','Tot_M\\n160': 'total_marks','TOT\\n160': 'total_marks',\n",
    "                 'P_C': 'phys_correct', 'P_W': 'phys_wrong', 'P_M\\n100': 'phy_tot',\n",
    "                 'C_C': 'chem_correct', 'C_W': 'chem_wrong', 'C_M\\n100': 'chem_tot',\n",
    "                 'Maths_CorrectMarks': 'math_correct',\n",
    "                 'Physics_CorrectMarks': 'phys_correct',\n",
    "                 'Chemistry_CorrectMarks': 'chem_correct',\n",
    "                 'Maths_WrongMarks': 'math_wrong',\n",
    "                 'Physics_WrongMarks': 'phys_wrong',\n",
    "                 'Chemistry_WrongMarks': 'chem_wrong',\n",
    "                 'Maths_Marks': 'math_tot',\n",
    "                 'Physics_Marks': 'phy_tot',\n",
    "                 'Chemistry_Marks': 'chem_tot',\n",
    "                 'Total_Marks': 'total_marks',\n",
    "                 'TOT_M\\n300': 'total_marks',\n",
    "                 'Rank': 'rank','TOT_R':'rank',\n",
    "                 'SEC': 'batch_at_exam'})\n",
    "\n",
    "        \n",
    "        standard_columns = [\n",
    "            'rollno', 'student_name', 'math_correct', 'phys_correct', 'chem_correct',\n",
    "            'math_wrong', 'phys_wrong', 'chem_wrong',\n",
    "            'math_tot', 'phy_tot', 'chem_tot',\n",
    "            'total_marks', 'rank', 'batch_at_exam'\n",
    "        ]\n",
    "        for col in standard_columns:\n",
    "            if col not in df.columns:\n",
    "                df[col] = None\n",
    "        df = df[standard_columns]\n",
    "        \n",
    "\n",
    "\n",
    "        # Metadata\n",
    "        df['exam_type'] = infer_exam_type(filename)\n",
    "        df['exam_date'] = infer_exam_date(filename)\n",
    "        df['filename'] = filename\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIPPED] {filepath}: {str(e)}\")\n",
    "        skipped_dir = os.path.join(\"data\", \"raw\", \"skipped\")\n",
    "        os.makedirs(skipped_dir, exist_ok=True)\n",
    "        shutil.move(filepath, os.path.join(skipped_dir, os.path.basename(filepath)))\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b34e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13894 entries, 0 to 13893\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   rollno         13894 non-null  int64  \n",
      " 1   student_name   13894 non-null  object \n",
      " 2   math_correct   10612 non-null  float64\n",
      " 3   phys_correct   10612 non-null  float64\n",
      " 4   chem_correct   10612 non-null  float64\n",
      " 5   math_wrong     10612 non-null  float64\n",
      " 6   phys_wrong     10612 non-null  float64\n",
      " 7   chem_wrong     10612 non-null  float64\n",
      " 8   math_tot       13894 non-null  int64  \n",
      " 9   phy_tot        13894 non-null  int64  \n",
      " 10  chem_tot       13894 non-null  int64  \n",
      " 11  total_marks    13894 non-null  int64  \n",
      " 12  rank           13894 non-null  int64  \n",
      " 13  batch_at_exam  13894 non-null  object \n",
      " 14  exam_type      13894 non-null  object \n",
      " 15  exam_date      13894 non-null  object \n",
      " 16  filename       13894 non-null  object \n",
      " 17  current_batch  13894 non-null  object \n",
      " 18  batch_changed  13894 non-null  object \n",
      "dtypes: float64(6), int64(6), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "student_data = pd.read_csv('data/student_performance_staging.csv')\n",
    "student_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c21ece",
   "metadata": {},
   "source": [
    "Notice non null values in all column except subject wise correct, and subject wise wrong column as those values was originally not present in Data and cannot be interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d9dbc",
   "metadata": {},
   "source": [
    "## üîß SQL Transformation Highlights\n",
    "\n",
    "- Standardized categorical values: Batch (`Grade1`, `GRADE1` ‚Üí `Grade 1`), Exam Type (WTM01 ‚Üí JEE Mains).\n",
    "- Created primary keys on `(rollno, exam_date, exam_type)`.\n",
    "- Built indexes on `rollno`, `exam_type`, and `exam_date` for query optimization.\n",
    "- Created SQL views to support business KPIs and dashboard filters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8690f",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "ALTER TABLE st.student_performance\n",
    "ADD clean_exam_type VARCHAR(50); \n",
    "\n",
    "UPDATE st.student_performance\n",
    "SET clean_exam_type =\n",
    "    CASE\n",
    "        WHEN exam_type IN ('ADV', 'ADV_P1', 'ADV_P2', 'WTA') THEN 'JEE ADVANCE'\n",
    "        WHEN exam_type IN ('WTM', 'PTM','PSPT') THEN 'JEE MAINS'\n",
    "        WHEN exam_type = 'BITSAT' THEN 'BITSAT'\n",
    "        WHEN exam_type = 'EAMCET' THEN 'EAMCET'\n",
    "        ELSE exam_type\n",
    "    END;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277eb6f8",
   "metadata": {},
   "source": [
    "##### Speeds up dashboards or reports filtered by exam_tpe  date ranges, etc.\n",
    "- CREATE INDEX idx_exam_type_date ON st.student_performance (exam_type, exam_date);\n",
    "\n",
    "\n",
    "\n",
    "##### Optimizes student-wise performance views or detailed reports.\n",
    "- CREATE INDEX idx_rollno ON st.student_performance (rollno);\n",
    "\n",
    "\n",
    "##### Helps with batch-level summaries or heatmaps in Tableau.\n",
    "\n",
    "\n",
    "- CREATE INDEX idx_batch_current ON st.student_performance (current_batch);\n",
    "\n",
    "\n",
    "##### Boosts joins or filters using multiple fields together (very common in views or stored procedures).\n",
    "- CREATE INDEX idx_rollno_exam ON st.student_performance (rollno, exam_type, exam_date);\n",
    "\n",
    "\n",
    "##### Optimize srollno, student_name performance \n",
    "- CREATE INDEX idx_rollno_batch ON st.student_performance (rollno,current_batch);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05a5e1",
   "metadata": {},
   "source": [
    "## ü§ñ Predictive Modeling: Forecasting Student JEE Scores\n",
    "\n",
    "This section focuses on predicting each student's total score in JEE Mains using historical test data. The modeling task is a regression problem, and we evaluated multiple models to identify the most accurate predictor.\n",
    "\n",
    "### üîç Models Trained:\n",
    "- **Linear Regression**\n",
    "- **Lasso Regression**\n",
    "- **Ridge Regression**\n",
    "- **XGBoost Regressor**\n",
    "\n",
    "### üìä Evaluation Metrics:\n",
    "\n",
    "| Model              | R¬≤ Score | RMSE  |\n",
    "|-------------------|----------|-------|\n",
    "| Linear Regression | 0.6415    | 29.22  |\n",
    "| Ridge Regression  | 0.6315     | 29.22 |\n",
    "| Lasso Regression  | 0.6317     | 29.21  |\n",
    "| XGBoost Regressor | **0.7920** | **21.95**  ‚úÖ |\n",
    "\n",
    "XGBoost outperformed all other models, delivering the highest R¬≤ and lowest RMSE. This model was chosen as the final predictor for student score forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Feature Importance (XGBoost)\n",
    "\n",
    "The top 6 features influencing student scores:\n",
    "\n",
    "![XGBoost Feature Importance](xgboost_feature_importance.png)\n",
    "\n",
    "- **physics_correct** had the highest impact on predicted scores.\n",
    "- **batch_rank_encoded** helped capture the influence of academic peer groups.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Prediction Workflow\n",
    "\n",
    "The final prediction system accepts a student‚Äôs latest test records and metadata (e.g., gender, batch, past subject scores) and returns an estimated JEE Mains score. We created a function `predict_total_marks(input_dict)` to standardize predictions across new inputs.\n",
    "\n",
    "### üéØ Use-Case Highlights:\n",
    "\n",
    "- **76%** of students were predicted within ¬±15 marks of their actual score.\n",
    "- Students flagged with scores below their batch average were marked as ‚Äúat-risk‚Äù.\n",
    "- Educators used this score to provide proactive support and personalized mentoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddee337d",
   "metadata": {},
   "source": [
    "## üìä Interactive Dashboards (Tableau)\n",
    "\n",
    "To make data-driven insights accessible to stakeholders, we developed **4 dynamic dashboards** using Tableau Public. These dashboards help academic decision-makers visually explore student performance, participation trends, prediction results, and batch-wise comparison.\n",
    "\n",
    "Each dashboard supports filters by **Exam Type**, **Batch**, **Gender**, and **Year**, and was built using anonymized student data.\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Dashboard 1: Overall Performance Trends\n",
    "\n",
    "![Dashboard 1](Dashboard_1_screenshot.png)\n",
    "\n",
    "**Visualizations:**\n",
    "- Batch-Wise bar charts shows Marks Distribution, Donut Chart shows: % Students in each Batch\n",
    "- Subject-wise bar charts: Avg marks, Positive/Negative split\n",
    "- Summary KPI tiles: Total Students, Class Average\n",
    "\n",
    "**Key Insights:**\n",
    "- Grade 5 and Grade 6 batches had the highest avg. marks (~116).\n",
    "- Physics emerged as the strongest subject; Chemistry showed higher negative marks.\n",
    "- Students made fewer mistakes in Math ‚Äî implying stronger clarity in that subject.\n",
    "\n",
    "---\n",
    "\n",
    "### üìò Dashboard 2: Exam Type Summary\n",
    "\n",
    "![Dashboard 2](Dashboard_2_screenshot.png)\n",
    "\n",
    "**Visualizations:**\n",
    "- Total exams conducted (BANs)\n",
    "- Bar chart: Average marks by exam type and Subject-Wise\n",
    "- Exam-wise student participation tracker\n",
    "- Score distributions by attempt group\n",
    "\n",
    "\n",
    "**Key Insights:**\n",
    "\n",
    "- JEE Mains was conducted 31 times ‚Äî the primary focus of the institute.\n",
    "- Students attempting 45+ tests scored 65% higher on average than those with <27 showing impact of Participation on Average Performance.\n",
    "- High engagement (top 2 attempt groups) = 51.2% of all students ‚Äî this group drives average performance.\n",
    "- 32.25% of Students group attempted test on an average from 35‚Äì41 times  achieved a 19.9% higher average score than group of Students who attempted test <27  (62.0 vs 56.9), suggesting that even moderate increase in participation lead to measurable gains.\n",
    "- Dashboard enabled early detection of low-participation patterns on specific dates.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### üßÆ Dashboard 3: Top vs Bottom N Performers\n",
    "\n",
    "![Dashboard 3](Dashboard_3_screenshot.png)\n",
    "\n",
    "**Visualizations:**\n",
    "- Subject-wise comparison between Top 10% and Bottom 10%\n",
    "- Batch distribution bar chart for each group\n",
    "- Score histograms and exam participation counts\n",
    "\n",
    "**Key Insights:**\n",
    "-  Difference between Maximum marks of Top Performer and bottom Performer is >100.\n",
    "- Grade 3,Grade5 batches dominated top N while Grade 8 showed up more in bottom N.\n",
    "- Bottom performers often skipped exams and showed erratic subject performance.\n",
    "- Helped surface high-potential students in mid-performing batches.\n",
    "- Bottom Performers show good performance in Eamcet as compare to other exams\n",
    "\n",
    "---\n",
    "\n",
    "### üìà Dashboard 4: Predicted vs Actual Score\n",
    "\n",
    "![Dashboard 4](Dashboard_4_screenshot.png)\n",
    "\n",
    "**Visualizations:**\n",
    "- Actual vs Predicted scatter plots\n",
    "- Residual error analysis\n",
    "- Student-level prediction table with risk status\n",
    "- Dynamic filters by batch and gender\n",
    "\n",
    "**Key Insights:**\n",
    "- Model correctly predicted scores for 76% students within ¬±15 marks.\n",
    "- Students flagged ‚Äúat-risk‚Äù based on predicted < batch avg. ‚Äî enabled proactive mentoring.\n",
    "- Residual plot showed tight clustering with few large deviations.\n",
    "\n",
    "---\n",
    "\n",
    "üìå These dashboards empowered teachers and coordinators to move from intuition-based judgment to data-backed academic planning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8614c",
   "metadata": {},
   "source": [
    "## üìå Key Insights & Recommendations\n",
    "\n",
    "### üéØ Actionable Business Insights\n",
    "\n",
    "- **43 students** were identified as *at-risk* based on predicted JEE scores and test participation patterns.\n",
    "- **4 high-potential students** surfaced from underperforming batches, opening opportunities for fast-tracking.\n",
    "- Students with **45+ test attempts** scored **65% higher on average** than those with fewer than 27 ‚Äî showing strong link between consistency and performance.\n",
    "- **Physics** consistently emerged as the top-performing subject across all exam types.\n",
    "- Negative marking was higher in **Chemistry**, especially among bottom 10% students.\n",
    "- Bottom 10% performers showed low engagement and frequent exam absenteeism.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Recommendations\n",
    "\n",
    "- üìå **Focus mentorship on Bottom 10% and Low Participation students** ‚Äî their average score was below 50, and they made up the smallest but most critical segment (6.8%).\n",
    "- üìå **Encourage students in the 35‚Äì41 test range** to attempt more ‚Äî even moderate increases in participation resulted in ~20% higher scores.\n",
    "- üìå **Track predicted scores monthly** ‚Äî flag those trending below batch average and initiate early intervention.\n",
    "- üìå **Continue reinforcing Physics teaching methodology**, while exploring ways to reduce negative marking in Chemistry.\n",
    "- üìå **Automate score prediction updates** with Python + SQL + scheduling tools, reducing manual workload by 40% (already implemented in earlier automation work).\n",
    "- üìå **Visualize exam participation date-wise** to identify dips in engagement ‚Äî allows timely rescheduling or student outreach.\n",
    "- üìå **Mention difficulty level of each exam subject wise and overall** help more personalized support for each student by knowing which topic they suffer most or excels in.\n",
    "\n",
    "---\n",
    "\n",
    "These insights directly contribute to improving academic planning, mentoring allocation, and student performance outcomes ‚Äî all backed by data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b5ed0c",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Tools & Skills Utilized\n",
    "\n",
    "- **Python**: Data cleaning, preprocessing, automation scripts, regression modeling\n",
    "- **Pandas & NumPy**: Data manipulation, missing value handling, feature engineering\n",
    "- **Scikit-learn**: Linear, Lasso, Ridge regression models, train-test split, evaluation\n",
    "- **XGBoost**: Final score prediction model with feature importance\n",
    "- **SQL (MSSQL Server)**: Data ingestion, cleaning, transformation, and view creation\n",
    "- **Tableau Public**: Dashboard creation with interactive filters and strategic KPIs\n",
    "- **Matplotlib & Seaborn**: Visual EDA and model evaluation\n",
    "- **GitHub**: Version control and project portfolio\n",
    "\n",
    "---\n",
    "\n",
    "## üí≠ Lessons Learned & Reflections\n",
    "\n",
    "This project deepened my ability to work across the entire data analytics pipeline ‚Äî from raw Excel data cleaning to SQL, predictive modeling, and interactive dashboard design.\n",
    "\n",
    "### Key Learnings:\n",
    "- **Dynamic data cleaning** is critical when working with real-world inconsistent educational data.\n",
    "- **SQL view creation and indexing** drastically improve dashboard performance and scalability.\n",
    "- **Feature selection and model tuning** are key to building reliable score predictors.\n",
    "- **Participation and behavioral data** often carry more predictive power than categorical attributes like gender or batch.\n",
    "\n",
    "Overcoming challenges such as missing records, inconsistent naming conventions, and integrating machine learning into a real-world education context significantly improved my problem-solving mindset and storytelling confidence.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
